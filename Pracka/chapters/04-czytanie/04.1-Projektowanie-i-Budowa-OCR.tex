\chapter{Odczytywanie losowego wyniku z kości}

---TODO graficzny schemat przepływu pracy---
\begin{verbatim}
    Maszyna (robot) wykonuje rzut kością
    Kamera umieszczona w jego górnej części robi zdjęcie
    Zdjęcie to jest przekazywane do algorytmu wykonującego preprocessing
    Następnie, wyuczony przez nas model SI odczytuje wyrzucony na kości wynik i zwraca cyfrę
    Cyfra jest przekazywana na wyjście
\end{verbatim}

\section{Przetwarzanie wstępne obrazów}

W niniejszym rozdziale omówiono proces przetwarzania wstępnego obrazów kości,
który przekształca dane pochodzące z fizycznego komponentu naszej maszyny (zdjęcia kości) na dane wejściowe dla modelu sztucznej inteligencji.
Przez dane wejściowe dla modelu SI rozumie się tutaj odpowiednio sformatowane obrazy, a więc takie w skali szarości,
o rozmiarach 64x64 piksele, zawierające jedynie kość wyciętą ze zdjęcia całego bębna maszyny.

\subsection{Algorytm}

Przetwarzanie obrazów składa się z kilku etapów, które dokładnie opisano poniżej, a przepływ pracy prezentuje się tak: \\
1. Wczytanie obrazu wejściowego \\
2. Odnalezienie kości za pomocą maski na komponencie nasycenia \\
3. Stworzenie i wycięcie ramki ograniczającej (ang. bounding box) wokół maski \\
4. Przeskalowanie do odpowiedniego rozmiaru \\
5. Konwersja do skali szarości \\
6. Zapisanie gotowego obrazu \\

Na rysunku \ref{fig:4combined} przedstawiono przykładowe zdjęcie surowe (część a)
oraz poddane wstępnemu przetwarzaniu (część b).


\begin{figure}[H]
    \centering
    \begin{subfigure}[t]{0.45\linewidth}
        \centering
        \includegraphics[width=\linewidth]{chapters/04-czytanie/figures/4raw}
        \caption{Surowe zdjęcie z kamery urządzenia.}
        \label{fig:4raw}
    \end{subfigure}
    \hfill
    \begin{subfigure}[t]{0.45\linewidth}
        \centering
        \includegraphics[width=\linewidth]{chapters/04-czytanie/figures/4processed}
        \caption{Zdjęcie poddane preprocessingowi.}
        \label{fig:4proc}
    \end{subfigure}
    \caption{Porównanie zdjęcia surowego i po preprocessing’u.}
    \label{fig:4combined}
\end{figure}


---- TODO ---- Czy np. dodać elementy pośrednie? - tak, dodam.


Przedstawiony algorytm został zaimplementowany w języku Python, a jego zadaniem jest identyfikacja, wycięcie i przeskalowanie obszarów zawierających obiekty zainteresowania w zdjęciach.

Zdjęcia w formacie JPEG są wczytywane za pomocą biblioteki Pillow, a następnie konwertowane do przestrzeni barw RGB, co zapewnia jednolitość formatów danych wejściowych.

Obrazy są przekształcane do przestrzeni barw HSV, aby oddzielić komponenty odpowiadające za barwę (H), nasycenie (S) oraz jasność (V).
Nasycenie jest następnie wygładzane przy użyciu filtru Gaussa:

--- TODO ---
jakieś cytowanie, o tym czemu filtr Gaussa?
oraz dodać coś o parametrach filtru, konkretnie

Na podstawie komponentu nasycenia za pomocą progowania tworzona jest maska binarna,
która identyfikuje obszary o wysokim nasyceniu (a więc naszą kość).

Próg został dobrany eksperymentalnie, kończąc na wartości *wartość!*, tak aby w kontrolowanym środowisku, jakim jest bęben robota,
przy stałym oświetleniu opisanym w poprzednim rozdziale generowana maska obejmowała obszar zainteresowania - kość, ale nie obejmowała tła (kubka).
Korzysta to przede wszystkim z tego że kubek został wytworzony z czarnego materiału, a używana kość jest jednolitego, jasnego koloru.

W celu usunięcia niewielkich luk w masce binarnej stosowana jest operacja zamknięcia morfologicznego.
Operacja ta jest szczególnie adekwatna w przypadku niejednolitej kości, takiej,
która zawierałaby obszary o wyższym, jak i o niższym nasyceniu.
W takim przypadku powstała maska mogłaby nie obejmować całej kości przy obecnie ustawionym progu nasycenia lub taka,
która obejmowałaby osobno dwie rozłączne części kości.
W związku z tym operacja domknięcia morfologicznego ujednolica maskę przed dalszym przetwarzaniem.

%% TODO - cytowanie o zamknięciu morfologicznym. \\

Następnie maska jest analizowana w celu zlokalizowania największego konturu <otaczającego> z wykorzystaniem strukturalnego elementu prostokątnego,
o dynamicznie dobranym rozmiarze obejmującym całość obliczonej w poprzednim kroku maski nasycenia,
którego implementacja została zaczerpnięta z biblioteki OpenCV [tu cytowanie], które określa obszar zainteresowania.

Na tej podstawie oryginalny obraz jest kadrowany w kształt prostokąta wokół obszaru zainteresowania,
a następnie przeskalowywany do wymiarów $64 \times 64$ pikseli.

%% --- TODO --- to cytowanie wyżej \\

Ostatecznie obraz jest konwertowany do skali szarości, co redukuje wymiarowość danych
i umożliwia naszej sieci neuronowej skupienie się na strukturze obrazu.

Dodatkowo, konwersja do skali szarości pozwala znacznie lepiej poradzić sobie z problemem odblasków,
powstających gdy kość niefortunnie ułoży się pod takim kątem, że odbija światło którejś z diód wprost do kamery.

\subsection{Potencjalne trudności}

Wspomniane wcześniej odblaski znacznie pogarszają skuteczność odczytywania wyniku z kostki.
Jednak zastosowanie skali szarości pozwoliło w znacznym stopniu pozbyć się tego problemu, co pokazują rysunki 4.3 oraz 4.4.

\begin{figure}[H]
    \centering
    \begin{subfigure}[t]{0.45\linewidth}
        \centering
        \includegraphics[width=\linewidth]{chapters/04-czytanie/figures/blask_raw}
        \caption{Odblask na przeskalowanym zdjęciu.}
        \label{fig:blaskraw}
    \end{subfigure}
    \hfill
    \begin{subfigure}[t]{0.45\linewidth}
        \centering
        \includegraphics[width=\linewidth]{chapters/04-czytanie/figures/blask_proc}
        \caption{Odblask po zmianie na skalę szarości.}
        \label{fig:blaskproc}
    \end{subfigure}
    \caption{Porównanie przetwarzania odblasku: część a) i b).}
    \label{fig:blaskcombined}
\end{figure}


Inną trudnością, która objawiała się w początkowych fazach pracy były zupełnie czarne obrazy,
w wyniku problemu z działaniem diod, o czym więcej będzie powiedziane w rozdziale o problemach
--- TODO --- Tak zakładam, że to powinno być w innym, bo to sprzętowe i średnio tu pasuje, chyba (?)

Kolejną, znacznie częściej spotykaną trudnością w obecnej architekturze urządzenia są niejednoznaczne wyniki,
a więc moment gdy kość zatrzyma się w pozycji w której widać więcej niż jedną ściankę.
Najczęściej jest to spowodowane tym, że kostka zatrzymała się na śmigle napędowym, przez co wynik może być niejednoznaczny.
% TODO check nazwy śmigło!!! XD

\begin{figure}[H]
    \centering
    \begin{subfigure}[t]{0.45\linewidth}
        \centering
        \includegraphics[width=\linewidth]{chapters/04-czytanie/figures/niepewne}
        \caption{Kość zatrzymana na śmigle (ujęcie 1).}
        \label{fig:niepewne}
    \end{subfigure}
    \hfill
    \begin{subfigure}[t]{0.45\linewidth}
        \centering
        \includegraphics[width=\linewidth]{chapters/04-czytanie/figures/smiglo}
        \caption{Kość zatrzymana na śmigle (ujęcie 2).}
        \label{fig:smiglo}
    \end{subfigure}
    \caption{Porównanie dwóch ujęć kości zatrzymanej na śmigle.}
    \label{fig:smiglocombined}
\end{figure}


Rozwiązaniem tego problemu jest model dokonujący klasyfikacji wyniku rzutu, który siłą rzeczy odczytuje ze zdjęcia tylko jeden wynik i wybiera ten,
który jest bardziej widoczny, ponieważ podczas uczenia został wyposażony również w takie niejednoznaczne sytuacje,
które byliśmy w stanie ręcznie oznaczyć właśnie na potrzeby nauczenia modelu.

Zdarzają się oczywiście rzadkie przypadki, w których kość wyląduje równo na śmigle, tak że wynik jest idealnie czytelny,
tak jakby wylądowała normalnie na podstawce kubka, ale wtedy problem z lądowaniem na śmigle nie istnieje,
gdyż nie przeszkadza to w tym że kość i tak zostanie podbita przy następnym obrocie śmigła.


Ostatnim rodzajem problemu jaki został napotkany był przypadek w którym kostka nie skończyła jeszcze swojej fazy lotu,
lub wpadła w bardzo długie wirowanie - efektywnie uniemożliwiając odczytanie wyniku.

\begin{figure}[H]
    \centering
    \begin{subfigure}[t]{0.45\linewidth}
        \centering
        \includegraphics[width=\linewidth]{chapters/04-czytanie/figures/wir}
        \caption{Wirująca kość.}
        \label{fig:wir}
    \end{subfigure}
    \hfill
    \begin{subfigure}[t]{0.45\linewidth}
        \centering
        \includegraphics[width=\linewidth]{chapters/04-czytanie/figures/wir2}
        \caption{Kość w ruchu.}
        \label{fig:wir2}
    \end{subfigure}
    \caption{Nieczytelne ujęcia wynikające z dłuższego niż przewidywany ruchu kości}
    \label{fig:wircombined}
\end{figure}


Rozwiązaniem większości wypadków w których zachodziła ta sytuacja okazało się spowolnienie działania maszyny.
Obecnie, oczekiwaniem aż kość zatrzyma się w miejscu steruje parametr czasowy, przyjmujący wartość jednej sekundy od zakończenia pracy śmigła.
Jest to wystarczające rozwiązanie, gdyż obecnie sytuacje niepewne z tego powodu zdarzają się bardzo rzadko (około 1 raz na 5000 rzutów).

Istnieje możliwość udoskonalenia tego rozwiązania, poprzez stosowanie detekcji ruchu kości,
jednak to rozwiązanie najpewniej okazałoby się bardziej kosztowne czasowo niż to proste czekanie stosowane obecnie.


--- TODO ---
jakoś to trzeba pewnie sprawdzić, bo nie mogę sobie tak gadać, nie?
Bo nie wiem, ale coś bym o tym pewnie napisał.
O, jednak można tak gadać, ale to nadal w TODO (for now!)



\subsection{Podsumowanie}

Przedstawiony algorytm przetwarzania wstępnego pozwala na skuteczne przygotowanie danych wejściowych dla modelu sztucznej inteligencji.
Automatyzuje proces identyfikacji i kadrowania obiektów zainteresowania w obrazach, co znacząco poprawia jakość danych.
Rozwiązanie zostało zaprojektowane z myślą o łatwej adaptacji do innych zastosowań wymagających podobnego przetwarzania obrazów,
dla przykładu przypadku zmiany kości w maszynie na inną, lub z inną ilością ścianek.

